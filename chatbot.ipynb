{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pinecone\n",
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel, TextEmbeddingModel\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "credential_path = \"YOUR CREDENTIAL.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"YOUR_ID\"  # @param {type:\"string\"}\n",
    "REGION = \"YOUR_REGION\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 67}},\n",
       " 'total_vector_count': 67}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import time\n",
    "\n",
    "pc = Pinecone(api_key=\"PINECONE API KEY\")\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    ")\n",
    "index_name = 'textbison-rag'\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=768,  # dimensionality of text-bison@002\n",
    "        metric='cosine',\n",
    "        spec=spec\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"prudential.csv\")\n",
    "dataset[\"Id\"] = dataset[\"Id\"].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm  # for progress bar\n",
    "\n",
    "data = dataset  # this makes it easier to iterate over the dataset\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    # get batch of data\n",
    "    batch = data.iloc[i:i_end]\n",
    "    # generate unique ids for each chunk\n",
    "    ids = [x['Id'] for _, x in batch.iterrows()]\n",
    "    # get text to embed\n",
    "    texts = [x['Content'] for _, x in batch.iterrows()]\n",
    "    # embed text\n",
    "    embeds = embed_model.embed_documents(texts)\n",
    "    # get metadata to store in Pinecone\n",
    "    metadata = [\n",
    "        {'text': x['Content'],\n",
    "        #  'source': x['source'],\n",
    "        'title': x['Title']} for i, x in batch.iterrows()\n",
    "    ]\n",
    "    # add to Pinecone\n",
    "    index.upsert(vectors=zip(ids, embeds, metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndex.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define utility functions\n",
    "def text_embedding(input_text) -> list:\n",
    "    embeddings = model.get_embeddings([input_text])\n",
    "    for embedding in embeddings:\n",
    "        vector = embedding.values\n",
    "        print(f\"Length of Embedding Vector: {len(vector)}\")\n",
    "    return vector\n",
    "\n",
    "def find_match(input_text):\n",
    "    input_em = text_embedding(input_text)\n",
    "    result = index.query(vector=input_em, top_k=10, includeMetadata=True)\n",
    "    return result['matches'][0]['metadata']['text'] + \"\\n\" + result['matches'][1]['metadata']['text']\n",
    "\n",
    "def query_refiner(conversation, query):\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@002\")\n",
    "    response = model.predict(\n",
    "        prompt=f\"Given the following user query and conversation log, formulate a question that would be the most relevant to provide the user with an answer from a knowledge base.\\n\\nCONVERSATION LOG: \\n{conversation}\\n\\nQuery: {query}\\n\\nRefined Query:\",\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=256,\n",
    "        top_p=0.5,\n",
    "        top_k=20\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize conversation components\n",
    "llm = ChatVertexAI(model_name=\"chat-bison\")\n",
    "buffer_memory = ConversationBufferWindowMemory(k=3, return_messages=True)\n",
    "\n",
    "system_msg_template = SystemMessagePromptTemplate.from_template(\n",
    "    template=\"\"\"Answer the question as truthfully as possible using the provided context, \n",
    "    and if the answer is not contained within the text below, say 'Sorry! I don't know'\"\"\"\n",
    ")\n",
    "human_msg_template = HumanMessagePromptTemplate.from_template(template=\"{input}\")\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    system_msg_template,\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    human_msg_template\n",
    "])\n",
    "conversation = ConversationChain(memory=buffer_memory, prompt=prompt_template, llm=llm, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize conversation history\n",
    "responses = [\"How can I help you today?\"]\n",
    "requests = []\n",
    "\n",
    "def get_conversation_history():\n",
    "    conversation_string = \"\"\n",
    "    for i in range(len(responses) - 1):\n",
    "        conversation_string += \"Human: \" + requests[i] + \"\\n\"\n",
    "        conversation_string += \"Bot: \" + responses[i + 1] + \"\\n\"\n",
    "    return conversation_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Refined Query:\n",
      " Apa itu Prudential Indonesia?\n",
      "Length of Embedding Vector: 768\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the question as truthfully as possible using the provided context, \n",
      "    and if the answer is not contained within the text below, say 'Sorry! I don't know'\n",
      "Human: Context:\n",
      "Beberapa produk yang ditawarkan oleh Prudential Indonesia yaitu: Asuransi Kesehatan, Asuransi Jiwa, Pendidikan, Perlindungan Bebas Premi, Produk Asuransi Yang Dikaitkan Investasi, Produk Syariah, Bancassurance, Perlindungan Karyawan.\n",
      "PT Prudential Life Assurance (Prudential Indonesia) didirikan pada 1995 dan merupakan bagian dari Prudential PLC, yang menyediakan asuransi jiwa dan kesehatan serta manajemen aset, dengan berfokus di Asia dan Afrika. Dengan menggabungkan pengalaman internasional Prudential di bidang asuransi jiwa dengan pengetahuan tata cara bisnis lokal, Prudential Indonesia memiliki komitmen untuk mengembangkan bisnisnya di Indonesia.\\n Prudential Indonesia telah menjadi pemimpin pasar untuk produk yang dikaitkan dengan investasi sejak lebih dari 20 tahun lalu.\\n Hingga 31 Desember 2022, Prudential Indonesia memiliki kantor pusat di Jakarta dengan 6 kantor pemasaran di Bandung, Semarang, Surabaya, Denpasar, Medan, dan Batam serta 356 Kantor Pemasaran Mandiri (KPM) di seluruh Indonesia. Sampai akhir 2022, didukung oleh lebih dari 150.000 Tenaga Pemasar berlisensi.\\n Prudential Indonesia berizin dan diawasi oleh Otoritas Jasa Keuangan (OJK). \n",
      "\n",
      " Query:\n",
      "Apa itu prudential Indonesia?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Bot:\n",
      " Prudential Indonesia adalah perusahaan asuransi jiwa dan kesehatan yang didirikan pada tahun 1995. Perusahaan ini merupakan bagian dari Prudential PLC, yang menyediakan asuransi jiwa dan kesehatan serta manajemen aset, dengan berfokus di Asia dan Afrika. Prudential Indonesia memiliki komitmen untuk mengembangkan bisnisnya di Indonesia dengan menggabungkan pengalaman internasional Prudential di bidang asuransi jiwa dengan pengetahuan tata cara bisnis lokal.\n",
      "\n",
      "Refined Query:\n",
      " Apa saja kelebihan Prudential Indonesia?\n",
      "Length of Embedding Vector: 768\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Answer the question as truthfully as possible using the provided context, \n",
      "    and if the answer is not contained within the text below, say 'Sorry! I don't know'\n",
      "Human: Context:\n",
      "Beberapa produk yang ditawarkan oleh Prudential Indonesia yaitu: Asuransi Kesehatan, Asuransi Jiwa, Pendidikan, Perlindungan Bebas Premi, Produk Asuransi Yang Dikaitkan Investasi, Produk Syariah, Bancassurance, Perlindungan Karyawan.\n",
      "PT Prudential Life Assurance (Prudential Indonesia) didirikan pada 1995 dan merupakan bagian dari Prudential PLC, yang menyediakan asuransi jiwa dan kesehatan serta manajemen aset, dengan berfokus di Asia dan Afrika. Dengan menggabungkan pengalaman internasional Prudential di bidang asuransi jiwa dengan pengetahuan tata cara bisnis lokal, Prudential Indonesia memiliki komitmen untuk mengembangkan bisnisnya di Indonesia.\\n Prudential Indonesia telah menjadi pemimpin pasar untuk produk yang dikaitkan dengan investasi sejak lebih dari 20 tahun lalu.\\n Hingga 31 Desember 2022, Prudential Indonesia memiliki kantor pusat di Jakarta dengan 6 kantor pemasaran di Bandung, Semarang, Surabaya, Denpasar, Medan, dan Batam serta 356 Kantor Pemasaran Mandiri (KPM) di seluruh Indonesia. Sampai akhir 2022, didukung oleh lebih dari 150.000 Tenaga Pemasar berlisensi.\\n Prudential Indonesia berizin dan diawasi oleh Otoritas Jasa Keuangan (OJK). \n",
      "\n",
      " Query:\n",
      "Apa itu prudential Indonesia?\n",
      "AI:  Prudential Indonesia adalah perusahaan asuransi jiwa dan kesehatan yang didirikan pada tahun 1995. Perusahaan ini merupakan bagian dari Prudential PLC, yang menyediakan asuransi jiwa dan kesehatan serta manajemen aset, dengan berfokus di Asia dan Afrika. Prudential Indonesia memiliki komitmen untuk mengembangkan bisnisnya di Indonesia dengan menggabungkan pengalaman internasional Prudential di bidang asuransi jiwa dengan pengetahuan tata cara bisnis lokal.\n",
      "Human: Context:\n",
      "Beberapa produk yang ditawarkan oleh Prudential Indonesia yaitu: Asuransi Kesehatan, Asuransi Jiwa, Pendidikan, Perlindungan Bebas Premi, Produk Asuransi Yang Dikaitkan Investasi, Produk Syariah, Bancassurance, Perlindungan Karyawan.\n",
      "Berikan perlindungan menyeluruh untuk Anda dan keluarga dengan produk asuransi jiwa seumur hidup dan asuransi jiwa berjangka yang dapat disesuaikan dengan kebutuhan dari Prudential Indonesia. Kelebihan:\\n 1.Beragam pilihan perlindungan: Pilihan perlindungan jiwa yang dapat disesuaikan dengan kebutuhan.\\n 2.Jangka waktu perlindungan: Pilihan jangka waktu perlindungan yang dapat direncanakan.\\n 3.Melindungi masa depan keluarga: Mempersiapkan kelangsungan hidup keluarga apabila terjadi risiko. \n",
      "\n",
      " Query:\n",
      "Apa kelebihannya?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Bot:\n",
      " Kelebihan asuransi jiwa dari Prudential Indonesia antara lain:\n",
      "1. Beragam pilihan perlindungan: Pilihan perlindungan jiwa yang dapat disesuaikan dengan kebutuhan.\n",
      "2. Jangka waktu perlindungan: Pilihan jangka waktu perlindungan yang dapat direncanakan.\n",
      "3. Melindungi masa depan keluarga: Mempersiapkan kelangsungan hidup keluarga apabila terjadi risiko.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(\"Query: \")\n",
    "    if query.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    # Process the query\n",
    "    conversation_history = get_conversation_history()\n",
    "    refined_query = query_refiner(conversation_history, query)\n",
    "    print(\"\\nRefined Query:\")\n",
    "    print(refined_query)\n",
    "    \n",
    "    context = find_match(refined_query)\n",
    "    response = conversation.predict(input=f\"Context:\\n{context} \\n\\n Query:\\n{query}\")\n",
    "    \n",
    "    # Update conversation history\n",
    "    requests.append(query)\n",
    "    responses.append(response)\n",
    "\n",
    "    # Display response\n",
    "    print(\"\\nBot:\")\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
